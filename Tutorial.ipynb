{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcHNFEcWJOuf"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4tMRNY6LB8zZ",
        "outputId": "3ebde1aa-d9ed-4c76-b414-bc657e5d8461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rating Dataframe\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "34953"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Item Dataframe\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Drama, Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fantasy, Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Comedy, Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  item_id           genres\n",
              "0       0  Romance, Action\n",
              "1       1          Mystery\n",
              "2       2   Drama, Western\n",
              "3       3  Fantasy, Horror\n",
              "4       4    Comedy, Drama"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# synthesize data\n",
        "NUM_USERS = 10_000\n",
        "NUM_ITEMS = 1_000\n",
        "user_id = np.arange(start = 0, stop = NUM_USERS)\n",
        "item_id = np.arange(start = 0, stop = NUM_ITEMS)\n",
        "np.random.seed(42)\n",
        "\n",
        "user_item_dict = defaultdict(list)\n",
        "genres = ['Action','Comedy','Drama','Fantasy','Horror','Mystery','Romance','Thriller','Western']\n",
        "for id in user_id:\n",
        "    \n",
        "    # random the number of item generation\n",
        "    # for each user, random 3 to 5 items to be rated.\n",
        "    num_rand_item = np.random.randint(low = 3, high = 5)\n",
        "\n",
        "    # random from the item_id\n",
        "    rand_items = np.random.choice(item_id, size = num_rand_item, replace = False)\n",
        "\n",
        "    # random rating for each itme_id\n",
        "    rand_rating = np.random.randint(low = 1, high = 10, size = num_rand_item)\n",
        "\n",
        "    # collect the user-item paris.\n",
        "    for uid, iid,rating in zip([id] * num_rand_item, rand_items, rand_rating):\n",
        "        user_item_dict['user_id'].append(uid)\n",
        "        user_item_dict['item_id'].append(iid)\n",
        "        user_item_dict['rating'].append(rating)\n",
        "\n",
        "# prepare dataframe\n",
        "ratings = pd.DataFrame(user_item_dict)\n",
        "print(\"Rating Dataframe\")\n",
        "ratings[['user_id','item_id']] = ratings[['user_id','item_id']].astype(str)\n",
        "display(len(ratings.index))\n",
        "\n",
        "item_genre_dict = defaultdict(list)\n",
        "for iid in item_id:\n",
        "\n",
        "    # random number of genres\n",
        "    num_rand_genre = np.random.randint(low = 1, high = 3)\n",
        "    # random set of genres\n",
        "    rand_genres = np.random.choice(genres, size = num_rand_genre, replace = False)\n",
        "    item_genre_dict['item_id'].append(iid)\n",
        "    item_genre_dict['genres'].append(', '.join(list(rand_genres)))\n",
        "\n",
        "# prepare dataframe\n",
        "items = pd.DataFrame(item_genre_dict)\n",
        "print(\"\\nItem Dataframe\")\n",
        "items = items.astype(str)\n",
        "display(items.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPSHx5UANsIb"
      },
      "source": [
        "# Popularity based\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "For any machine learning problems, we need a baseline model or method to use as a reference whether our approach is good or not.\n",
        "\n",
        "Our machine learning prediction or sophsticated analysis should, at least, beat those baseline performance.\n",
        "\n",
        "For recommendation system, we can make a simple baseline score with popular item recommendation\n",
        "\n",
        "To define the popularity of the item, there have a metrics called weighted rating system that is used to score the rating of each movie.\n",
        "\n",
        "Here is the formula\n",
        "\n",
        "```\n",
        "(WR) = (v ÷ (v+m)) × R + (m ÷ (v+m)) × C\n",
        "```\n",
        "Where\n",
        "- R = average rating for the movie. (rating)\n",
        "- v = number of votes for the movie. (members)\n",
        "- m = minimum votes required to be listed in the Top 250 (defined by > percentile 80 of total votes)\n",
        "- C = the average rating across the whole dataset.\n",
        "\n",
        "**Drawback**\n",
        "\n",
        "- It's not personalized. All the users will get the same exact list of popularity based recommendation.\n",
        "\n",
        "**Action**\n",
        "\n",
        "- For new users, if we don't have any information about them we can provide the list based on ranking the vote_count or weighted_rating as a best guess.\n",
        "In real world, this is the result when you see the section \"Popular on Netflix\"\n",
        "\n",
        "**Reference**\n",
        "\n",
        "- [IMDB rating system](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV?ref_=helpms_helpart_inline#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tw7HGVGWJTer",
        "outputId": "b23d0dfa-8bd0-4715-f99b-5fb390f9114d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def weighted_rating(v,m,R,C):\n",
        "    '''\n",
        "    Calculate the weighted rating\n",
        "    \n",
        "    Args:\n",
        "    v -> average rating for each item (float)\n",
        "    m -> minimum votes required to be classified as popular (float)\n",
        "    R -> average rating for the item (pd.Series)\n",
        "    C -> average rating for the whole dataset (pd.Series)\n",
        "    \n",
        "    Returns:\n",
        "    pd.Series\n",
        "    '''\n",
        "    return ( (v / (v + m)) * R) + ( (m / (v + m)) * C )\n",
        "\n",
        "def assign_popular_based_score(rating_df, item_df, user_col, item_col, rating_col):\n",
        "    '''\n",
        "    Assigned popular based score based on the IMDB weighted average.\n",
        "    \n",
        "    Args:\n",
        "    rating -> pd.DataFrame contains ['item_id', 'rating'] for each user.\n",
        "    \n",
        "    Returns\n",
        "    popular_items -> pd.DataFrame contains item and IMDB weighted score.\n",
        "    '''\n",
        "    \n",
        "    # pre processing\n",
        "    vote_count = (\n",
        "        rating_df\n",
        "        .groupby(item_col,as_index=False)\n",
        "        .agg( {user_col:'count', rating_col:'mean'} )\n",
        "        )\n",
        "    vote_count.columns = [item_col, 'vote_count', 'avg_rating']\n",
        "    \n",
        "    # calcuate input parameters\n",
        "    C = np.mean(vote_count['avg_rating'])\n",
        "    m = np.percentile(vote_count['vote_count'], 70)\n",
        "    vote_count = vote_count[vote_count['vote_count'] >= m]\n",
        "    R = vote_count['avg_rating']\n",
        "    v = vote_count['vote_count']\n",
        "    vote_count['weighted_rating'] = weighted_rating(v,m,R,C)\n",
        "    \n",
        "    # post processing\n",
        "    vote_count = vote_count.merge(item_df, on = [item_col], how = 'left')\n",
        "    popular_items = vote_count.loc[:,[item_col, 'genres', 'vote_count', 'avg_rating', 'weighted_rating']]\n",
        "    \n",
        "    return popular_items\n",
        "\n",
        "# init constant\n",
        "USER_COL = 'user_id'\n",
        "ITEM_COL = 'item_id'\n",
        "RATING_COL = 'rating'\n",
        "\n",
        "# calcualte popularity based\n",
        "pop_items = assign_popular_based_score(ratings, items, USER_COL, ITEM_COL, RATING_COL)\n",
        "pop_items = pop_items.sort_values('weighted_rating', ascending = False)\n",
        "\n",
        "# plot the popularity based on the weighted score\n",
        "fix, ax = plt.subplots(figsize=(9,6))\n",
        "sns.barplot(data = pop_items.head(10),\n",
        "            y = 'item_id',\n",
        "            x = 'weighted_rating',\n",
        "            palette = 'mako');\n",
        "sns.despine();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EHqK1l0KE-j"
      },
      "source": [
        "# Content based \n",
        "\n",
        "**Introduction**\n",
        "\n",
        "For example, if a person has liked the movie “Inception”, then this algorithm will recommend movies that fall under the same genre.\n",
        "\n",
        "Here we create a better way of recommendation by introducing other features of the content into our engine.\n",
        "\n",
        "It's an improvement compared to the popularity based recommendation we mentioned earlier.\n",
        "\n",
        "Now, the customer who read, watch, or like any kinds of specific products will get a recommendation based on the product they interacted in the past.\n",
        "\n",
        "Consider the example of Netflix. They save all the information related to each user in a vector form. This vector contains the past behavior of the user, i.e. the movies liked/disliked by the user and the ratings given by them. This vector is known as the profile vector. All the information related to movies is stored in another vector called the item vector. Item vector contains the details of each movie, like genre, cast, director, etc. The content-based filtering algorithm finds the cosine of the angle between the profile vector and item vector, i.e. cosine similarity.\n",
        "\n",
        "**Drawback**\n",
        "\n",
        "A major drawback of this algorithm is that it is limited to recommending items that are of the same type.\n",
        "It will never recommend products which the user has not bought or liked in the past. So if a user has watched or liked only action movies in the past, the system will recommend only action movies.\n",
        "\n",
        "**Reference**\n",
        "\n",
        "[Building a movie content based recommender using tf-idf](https://towardsdatascience.com/content-based-recommender-systems-28a1dbd858f5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J4YXYjEuK1C2",
        "outputId": "3b2c7d40-dad7-498c-ab82-0583749d9315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>211</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>352</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>512</td>\n",
              "      <td>Action, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>618</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>737</td>\n",
              "      <td>Action, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>744</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>813</th>\n",
              "      <td>813</td>\n",
              "      <td>Action, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>858</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id           genres\n",
              "0         0  Romance, Action\n",
              "99       99  Romance, Action\n",
              "211     211  Romance, Action\n",
              "352     352  Romance, Action\n",
              "512     512  Action, Romance\n",
              "618     618  Romance, Action\n",
              "737     737  Action, Romance\n",
              "744     744  Romance, Action\n",
              "813     813  Action, Romance\n",
              "858     858  Romance, Action"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def top_k_items(item_id, top_k, corr_mat, map_name):\n",
        "    \n",
        "    # sort correlation value ascendingly and select top_k item_id\n",
        "    top_items = corr_mat[item_id,:].argsort()[-top_k:][::-1] \n",
        "    top_items = [map_name[e] for e in top_items] \n",
        "\n",
        "    return top_items\n",
        "\n",
        "# preprocessing\n",
        "rated_items = items.loc[items[ITEM_COL].isin(ratings[ITEM_COL])].copy()\n",
        "\n",
        "# extract the genre\n",
        "genre = rated_items['genres'].str.split(\",\", expand=True)\n",
        "\n",
        "# get all possible genre\n",
        "all_genre = set()\n",
        "for c in genre.columns:\n",
        "    distinct_genre = genre[c].str.lower().str.strip().unique()\n",
        "    all_genre.update(distinct_genre)\n",
        "all_genre.remove(None)\n",
        "\n",
        "# create item-genre matrix\n",
        "item_genre_mat = rated_items[[ITEM_COL, 'genres']].copy()\n",
        "item_genre_mat['genres'] = item_genre_mat['genres'].str.lower().str.strip()\n",
        "\n",
        "# OHE the genres column\n",
        "for genre in all_genre:\n",
        "    item_genre_mat[genre] = np.where(item_genre_mat['genres'].str.contains(genre), 1, 0)\n",
        "item_genre_mat = item_genre_mat.drop(['genres'], axis=1)\n",
        "item_genre_mat = item_genre_mat.set_index(ITEM_COL)\n",
        "\n",
        "# compute similarity matix\n",
        "corr_mat = cosine_similarity(item_genre_mat)\n",
        "\n",
        "# get top-k similar items\n",
        "ind2name = {ind:name for ind,name in enumerate(item_genre_mat.index)}\n",
        "name2ind = {v:k for k,v in ind2name.items()}\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "# display result\n",
        "print(\"The top-k similar movie to item_id 99\")\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])\n",
        "\n",
        "del corr_mat\n",
        "gc.collect();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jme6wp0MK1ng"
      },
      "source": [
        "Summary\n",
        "\n",
        "As we expect, all the similar items interm of genre is in the top-k recommendation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0LqiAD4JIut"
      },
      "source": [
        "# Collaborative filtering\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "The collaborative filtering algorithm uses “User Behavior” for recommending items. This is one of the most commonly used algorithms in the industry as it is not dependent on any additional information.\n",
        "\n",
        "There are 2 ways we can make a prediction using the collaborative filtering technique.\n",
        "\n",
        "1. User based - The user-similarity matrix will consist of some distance metric that measures the similarity between any two pairs of users.\n",
        "This algorithm is useful when the number of users is less. Its not effective when there are a large number of users as it will take a lot of time to compute the similarity between all user pairs. This leads us to item-item collaborative filtering, which is effective when the number of users is more than the items being recommended.\n",
        "\n",
        "2. Item based - Likewise, the item-similarity matrix will measure the similarity between any two pairs of items.\n",
        "\n",
        "**Drawback**\n",
        "\n",
        "What will happen if a new user or a new item is added in the dataset? The answer is we can't make a prediction for that user or item because we don't have enough \"User behavior\" information. This problem is called a Cold Start. \n",
        "\n",
        "There are two types of cold start.\n",
        "1. User - Since there is no history of that user, the system does not know the preferences of that user\n",
        "These can be determined by what has been popular recently overall or regionally.\n",
        "\n",
        "2. Item - More the interaction a product receives, the easier it is for our model to recommend that product to the right user.\n",
        "We can make use of Content based filtering to solve this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w9c4fVUR2Zp"
      },
      "source": [
        "## 3.1 Memory based approache\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "The key difference of memory-based approach from the model-based techniques is that we are not learning any parameter using gradient descent (or any other optimization algorithm). The closest user or items are calculated only by using Cosine similarity or Pearson correlation coefficients, which are only based on arithmetic operations. various-implementations-of-collaborative-filtering\n",
        "\n",
        "Memory-based methods use user rating historical data to compute the similarity between users or items. The idea behind these methods is to define a similarity measure between users or items, and find the most similar to recommend unseen items. Building a memory based collaborative filtering recommender\n",
        "\n",
        "**Drawback**\n",
        "\n",
        "It's not scalable due to the sprasity of the data.\n",
        "We needs to construct the similarity matrix everytime the new user comes. (Hard to maintain, and operationalize)\n",
        "\n",
        "**Action**\n",
        "\n",
        "- The list result can be showed in the front-end application like \"Made for you\" -> Provide the list of recommended items.\n",
        "- The list result can be showed in the front-end application like \"Because you like item\" -> Provided the list of recommended items.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZQU_akPFSsft",
        "outputId": "8befbfb0-7a87-46b9-d81a-279165caff47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsity: 0.35%. This means that 0.35% of the user-item ratings have a value.\n",
            "\n",
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>248</td>\n",
              "      <td>Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>352</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>392</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>507</td>\n",
              "      <td>Horror, Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>570</td>\n",
              "      <td>Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>730</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>757</td>\n",
              "      <td>Romance, Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>824</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>899</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id             genres\n",
              "99       99    Romance, Action\n",
              "248     248             Horror\n",
              "352     352    Romance, Action\n",
              "392     392    Romance, Action\n",
              "507     507    Horror, Western\n",
              "570     570             Horror\n",
              "730     730            Fantasy\n",
              "757     757  Romance, Thriller\n",
              "824     824            Fantasy\n",
              "899     899             Comedy"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# preprocess data\n",
        "row = ratings[USER_COL]\n",
        "col = ratings[ITEM_COL]\n",
        "data = ratings[RATING_COL]\n",
        "\n",
        "# init user-item matrix\n",
        "mat = csr_matrix((data, (row, col)), shape=(NUM_USERS, NUM_ITEMS))\n",
        "mat.eliminate_zeros()\n",
        "\n",
        "# calculate sparsity\n",
        "sparsity = float(len(mat.nonzero()[0]))\n",
        "sparsity /= (mat.shape[0] * mat.shape[1])\n",
        "sparsity *= 100\n",
        "print(f'Sparsity: {sparsity:4.2f}%. This means that {sparsity:4.2f}% of the user-item ratings have a value.')\n",
        "\n",
        "# compute similarity\n",
        "item_corr_mat = cosine_similarity(mat.T)\n",
        "\n",
        "# get top k item\n",
        "print(\"\\nThe top-k similar movie to item_id 99\")\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = item_corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vbEOgthUOk1"
      },
      "source": [
        "Summary\n",
        "\n",
        "Now, we will get the different set of result from the content-based. The similaity between items has been calculated based on the \"User-behavior\" rather than the attributes of the items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgfvmPF9UcKa"
      },
      "source": [
        "## 3.2 Model-based approach¶\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "Model-based CF uses machine learning algorithms to predict users’ rating of unrated items. \n",
        "There are many model-based CF algorithms, the most commonly used are matrix factorization models such as to applying a SVD to reconstruct the rating matrix, latent Dirichlet allocation or Markov decision process based models. Building a memory based collaborative filtering recommender\n",
        "\n",
        "**Type**\n",
        "\n",
        "- Matrix Factorization (MF) based\n",
        "    1. TruncatedSVD (Sklearn)\n",
        "    2. Funk MF (Surprise)\n",
        "    3. Non negative MF (Surprise)\n",
        "- Deep learning MF based\n",
        "    1. Generalizaed MF (Keras)\n",
        "    2. Neural Collaborative filtering (Recommenders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r6-BQeiVeD9"
      },
      "source": [
        "### 3.2.1 TrucatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iwNSoyueWX9U",
        "outputId": "d0ab8c8d-f10a-4504-87eb-0667b9955472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>90</td>\n",
              "      <td>Action, Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>359</td>\n",
              "      <td>Horror, Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>521</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>568</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>629</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>802</td>\n",
              "      <td>Mystery, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832</th>\n",
              "      <td>832</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>885</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id           genres\n",
              "75       75          Romance\n",
              "90       90  Action, Fantasy\n",
              "99       99  Romance, Action\n",
              "359     359  Horror, Mystery\n",
              "521     521         Thriller\n",
              "568     568          Romance\n",
              "629     629         Thriller\n",
              "802     802  Mystery, Action\n",
              "832     832           Action\n",
              "885     885          Romance"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "epsilon = 1e-9\n",
        "n_latent_factors = 10\n",
        "\n",
        "# calculate item latent matrix\n",
        "item_svd = TruncatedSVD(n_components = n_latent_factors)\n",
        "item_features = item_svd.fit_transform(mat.transpose()) + epsilon\n",
        "\n",
        "# calculate user latent matrix\n",
        "user_svd = TruncatedSVD(n_components = n_latent_factors)\n",
        "user_features = user_svd.fit_transform(mat) + epsilon\n",
        "\n",
        "# compute similarity\n",
        "item_corr_mat = cosine_similarity(item_features)\n",
        "\n",
        "# get top k item\n",
        "print(\"\\nThe top-k similar movie to item_id 99\")\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = item_corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])\n",
        "\n",
        "del user_features\n",
        "gc.collect();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac5z421WWm1Q"
      },
      "source": [
        "Summary\n",
        "\n",
        "With this method, you can see that we can compute the similarity based on the specific number of latent factor.\n",
        "\n",
        "Now, the recommendation would be based on some latent factors that we cannot explain directly.\n",
        "But in mathematically speaking, it will be the top latent factor that minimize the loss between the Actual rating and Reconstructed rating.\n",
        "You can see that now we reduce the size of matrix compared to the one in memory-based approach. however, it's still not good enough approach because eventually when the user, or item size growing with the time.\n",
        "Soon it will reach the limitation of computation resouce as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loRUBhr8W3fk"
      },
      "source": [
        "### 3.2.2 Funk MF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O4-ouJ27XXCm"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-surprise -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L7Imga3WW6I_",
        "outputId": "dce2a867-82bd-4bee-ed05-2feee404755e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 2.6256\n",
            "\n",
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>114</td>\n",
              "      <td>Thriller, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>180</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>194</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>366</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>546</td>\n",
              "      <td>Action, Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>599</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>611</td>\n",
              "      <td>Drama, Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>771</td>\n",
              "      <td>Romance, Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>801</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id             genres\n",
              "99       99    Romance, Action\n",
              "114     114  Thriller, Romance\n",
              "180     180             Comedy\n",
              "194     194            Mystery\n",
              "366     366             Action\n",
              "546     546   Action, Thriller\n",
              "599     599            Romance\n",
              "611     611      Drama, Comedy\n",
              "771     771   Romance, Western\n",
              "801     801              Drama"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from surprise import SVD, accuracy\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection.split import train_test_split\n",
        "\n",
        "def pred2dict(predictions, top_k=None):\n",
        "    \n",
        "    rec_dict = defaultdict(list)\n",
        "    for user_id, item_id, actual_rating, pred_rating, _ in predictions:\n",
        "        rec_dict[user_id].append((item_id, pred_rating))        \n",
        "        \n",
        "    return rec_dict\n",
        "\n",
        "def get_top_k_recommendation(rec_dict, user_id, top_k, ind2name):\n",
        "    \n",
        "    pred_ratings = rec_dict[user_id]\n",
        "    # sort descendingly by pred_rating\n",
        "    pred_ratings = sorted(pred_ratings, key=lambda x: x[1], reverse=True)\n",
        "    pred_ratings = pred_ratings[:top_k]\n",
        "    recs = [ind2name[e[0]] for e in pred_ratings]\n",
        "    \n",
        "    return recs\n",
        "\n",
        "# prepare train and test sets\n",
        "reader = Reader(rating_scale=(1,10))\n",
        "data = Dataset.load_from_df(ratings, reader)\n",
        "train, test = train_test_split(data, test_size=.2, random_state=42)\n",
        "\n",
        "# init and fit the funk mf model\n",
        "algo = SVD(random_state = 42)\n",
        "algo.fit(train)\n",
        "pred = algo.test(test);\n",
        "\n",
        "# evaluation the test set\n",
        "accuracy.rmse(pred)\n",
        "\n",
        "# extract the item features from algo\n",
        "item_corr_mat = cosine_similarity(algo.qi)\n",
        "\n",
        "print(\"\\nThe top-k similar movie to item_id 99\")\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = item_corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])\n",
        "\n",
        "del item_corr_mat\n",
        "gc.collect();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlVYFT5LYB1m"
      },
      "source": [
        "Summary\n",
        "\n",
        "Here we use the Funk MF algorithms to create the latent factors matrix, and now we can build both the user-based, item-based recommendation.\n",
        "We also randomly split out some users from the train set into the test set for the validation purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upcYlKRkXV2V"
      },
      "source": [
        "### 3.2.3 Deep learning MF - Generalized Matrix Factorization (MF)\n",
        "Usually, in the MF method, we tried to learn the user-item interaction or tried to reconstruct the predicted rating with the inner product of the shared lated features.\n",
        "\n",
        "Now, for the deep learning approach, we use the different internal engine which is the DNNs to estimate the user and item laten features. We estimate the shared latent feature minimizing the target loss function.\n",
        "\n",
        "After that, we used the fitted model to predict the pair of item that each customer have never watched to see what to recommend next.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KIxzJwaLaOHY"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "givA5CGbaUD9",
        "outputId": "fbb5642d-7447-4f55-e622-8a61f9b5a2d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorflow_version` not found.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "Y2zBc5j7Xrt1",
        "outputId": "eea1dd96-695a-4c69-d27f-3551420ee0d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-24 12:40:23.038394: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2021-12-24 12:40:23.038415: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
            "2021-12-24 12:40:24.186986: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2021-12-24 12:40:24.187007: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2021-12-24 12:40:24.187021: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (iidoom-computer): /proc/driver/nvidia/version does not exist\n",
            "2021-12-24 12:40:24.187210: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation on the test set:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'root_mean_squared_error': 2.574052333831787,\n",
              " 'loss': 6.0513386726379395,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 6.0513386726379395}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>64</td>\n",
              "      <td>Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>219</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>258</td>\n",
              "      <td>Fantasy, Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>339</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>415</td>\n",
              "      <td>Romance, Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>425</td>\n",
              "      <td>Mystery, Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>485</td>\n",
              "      <td>Drama, Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>513</td>\n",
              "      <td>Mystery, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>901</th>\n",
              "      <td>901</td>\n",
              "      <td>Mystery, Western</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id             genres\n",
              "64       64            Western\n",
              "99       99    Romance, Action\n",
              "219     219            Romance\n",
              "258     258  Fantasy, Thriller\n",
              "339     339            Fantasy\n",
              "415     415     Romance, Drama\n",
              "425     425    Mystery, Horror\n",
              "485     485     Drama, Fantasy\n",
              "513     513    Mystery, Action\n",
              "901     901   Mystery, Western"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from typing import Dict, Text, Tuple\n",
        "\n",
        "def df_to_ds(df):\n",
        "\n",
        "    # convert pd.DataFrame to tf.data.Dataset\n",
        "    ds = tf.data.Dataset.from_tensor_slices(\n",
        "        (dict(df[['user_id','item_id']]), df['rating']))\n",
        "    \n",
        "    # convert Tuple[Dict[Text, tf.Tensor], tf.Tensor] to Dict[Text, tf.Tensor]\n",
        "    ds = ds.map(lambda x, y: {\n",
        "    'user_id' : x['user_id'],\n",
        "    'item_id' : x['item_id'],\n",
        "    'rating' : y\n",
        "    })\n",
        "\n",
        "    return ds.batch(256)\n",
        "\n",
        "class RankingModel(keras.Model):\n",
        "\n",
        "    def __init__(self, user_id, item_id, embedding_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        # user model\n",
        "        input = keras.Input(shape=(), dtype=tf.string)\n",
        "        x = keras.layers.StringLookup(\n",
        "            vocabulary = user_id, mask_token = None\n",
        "            )(input)\n",
        "        output = keras.layers.Embedding(\n",
        "            input_dim = len(user_id) + 1,\n",
        "            output_dim = embedding_size,\n",
        "            name = 'embedding'\n",
        "        )(x)\n",
        "        self.user_model = keras.Model(inputs = input,\n",
        "                                      outputs = output,\n",
        "                                      name = 'user_model')\n",
        "\n",
        "        # item model\n",
        "        input = keras.Input(shape=(), dtype=tf.string)\n",
        "        x = keras.layers.StringLookup(\n",
        "            vocabulary = item_id, mask_token = None\n",
        "            )(input)\n",
        "        output = keras.layers.Embedding(\n",
        "            input_dim = len(item_id) + 1,\n",
        "            output_dim = embedding_size,\n",
        "            name = 'embedding'\n",
        "        )(x)\n",
        "        self.item_model = keras.Model(inputs = input,\n",
        "                                  outputs = output,\n",
        "                                  name = 'item_model')\n",
        "\n",
        "        # rating model\n",
        "        user_input = keras.Input(shape=(embedding_size,), name='user_emb')\n",
        "        item_input = keras.Input(shape=(embedding_size,), name='item_emb')\n",
        "        x = keras.layers.Concatenate(axis=1)([user_input, item_input])\n",
        "        x = keras.layers.Dense(256, activation = 'relu')(x)\n",
        "        x = keras.layers.Dense(64, activation = 'relu')(x)\n",
        "        output = keras.layers.Dense(1)(x)\n",
        "        \n",
        "        self.rating_model = keras.Model(\n",
        "            inputs = {\n",
        "                'user_id' : user_input,\n",
        "                'item_id' : item_input\n",
        "            },\n",
        "            outputs = output,\n",
        "            name = 'rating_model'\n",
        "        )\n",
        "\n",
        "    def call(self, inputs: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "\n",
        "        user_emb = self.user_model(inputs['user_id'])\n",
        "        item_emb = self.item_model(inputs['item_id'])\n",
        "\n",
        "        prediction = self.rating_model({\n",
        "            'user_id' : user_emb,\n",
        "            'item_id' : item_emb\n",
        "        })\n",
        "        \n",
        "        return prediction\n",
        "\n",
        "class GMFModel(tfrs.models.Model):\n",
        "\n",
        "    def __init__(self, user_id, item_id, embedding_size):\n",
        "        super().__init__()\n",
        "        self.ranking_model = RankingModel(user_id, item_id, embedding_size)\n",
        "        self.task = tfrs.tasks.Ranking(\n",
        "            loss = keras.losses.MeanSquaredError(),\n",
        "            metrics = [keras.metrics.RootMeanSquaredError()]\n",
        "        )\n",
        "    \n",
        "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "        \n",
        "        return self.ranking_model(\n",
        "            {\n",
        "             'user_id' : features['user_id'], \n",
        "             'item_id' : features['item_id']\n",
        "            })\n",
        "\n",
        "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "\n",
        "        return self.task(labels = features.pop('rating'),\n",
        "                         predictions = self.ranking_model(features))\n",
        "\n",
        "# preprocess\n",
        "train, test = train_test_split(ratings, train_size = .8, random_state=42)\n",
        "train, test = df_to_ds(train), df_to_ds(test)\n",
        "\n",
        "# # init model\n",
        "embedding_size = 64\n",
        "model = GMFModel(user_id.astype(str),\n",
        "                 item_id.astype(str),\n",
        "                 embedding_size)\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adagrad(learning_rate = .01)\n",
        ")\n",
        "\n",
        "# # fitting the model\n",
        "model.fit(train, epochs=3, verbose=0)\n",
        "\n",
        "# evaluate with the test data\n",
        "result = model.evaluate(test, return_dict=True, verbose=0)\n",
        "print(\"\\nEvaluation on the test set:\")\n",
        "display(result)\n",
        "\n",
        "# extract item embedding\n",
        "item_emb = model.ranking_model.item_model.layers[-1].get_weights()[0]\n",
        "\n",
        "\n",
        "item_corr_mat = cosine_similarity(item_emb)\n",
        "\n",
        "print(\"\\nThe top-k similar movie to item_id 99\")\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = item_corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])\n",
        "\n",
        "del item_corr_mat\n",
        "gc.collect();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwZ9L81RmSW0"
      },
      "source": [
        "### 3.2.4 Deep learning MF - Neural Collaborative Filtering (NCF)\n",
        "\n",
        "Due to the library conflie, remove the implementation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
